	<aside>
		<dl>
			<dt>Timeframe</dt>
			<dd>September &ndash; October 2008</dd>
			<dt>Role</dt>
			<dd>Development</dd>
			<dd>Ideation</dd>
			<dt>Team</dt>
			<dd><a href="http://tonydewan.com" rel="friend met colleague">Tony Dewan</a></dd>
			<dt>Visit</dt>
			<dd><a href="http://pingplatform.org">http://pingplatform.org</a></dd>
		</dl>
	</aside>
	
	<h2>{{{summary}}}</h2>

	<figure class="caption">
		<object type="application/x-shockwave-flash" width="640" height="480" data="http://www.flickr.com/apps/video/stewart.swf?v=71377" classid="clsid:D27CDB6E-AE6D-11cf-96B8-444553540000"> <param name="flashvars" value="intl_lang=en-us&photo_secret=b98cda52cf&photo_id=3567110476"></param> <param name="movie" value="http://www.flickr.com/apps/video/stewart.swf?v=71377"></param> <param name="bgcolor" value="#000000"></param> <param name="allowFullScreen" value="true"></param><embed type="application/x-shockwave-flash" src="http://www.flickr.com/apps/video/stewart.swf?v=71377" bgcolor="#000000" allowfullscreen="true" flashvars="intl_lang=en-us&photo_secret=b98cda52cf&photo_id=3567110476" height="480" width="640"></embed></object>
		<p><strong>1</strong> Demo of a Ping Pong game using only hand gestures.</p>
	</figure>

	<h3>Concept</h3>
	<p>As a first attempt into exploring physical computing, colleague <a href="http://tonydewan.com" rel="friend met colleague">Tony Dewan</a> and I imagined an interactive gaming tabletop surface, with both hardware and software open-sourced. The finished table would be ideally installed on the <a href="http://www.iupui.edu/"><abbr title="Indiana University-Purdue University of Indianapolis">IUPUI</abbr></a> campus, freely available to the student populous. With the <a href="http://informatics.iupui.edu/">School of Informatics</a> students in mind, Ping's software layer would be built upon the familiar Adobe Flex API, allowing student developers to freely publish games to the public platform and providing them a unique opportunity to design for gestural interfaces.</p>
	
	<h3>Gestural input</h3>
	<figure class="caption aside">
		<a href="http://www.flickr.com/photos/65471246@N00/3567133800/"><img src="http://farm4.static.flickr.com/3309/3567133800_3e7331f645.jpg" width="300" height="400" alt="Interactive area" /></a>
		<p><strong>2</strong> Horizontal hand placement acts as the primary input method.</p>
	</figure>
	<figure class="caption aside clear">
		<a href="http://www.flickr.com/photos/65471246@N00/3566413373/"><img src="http://farm4.static.flickr.com/3564/3566413373_297205cd86.jpg" width="300" height="200" alt="Mounted sensor and adapter" /></a>
		<p><strong>3</strong> A sensor block with two mounted IR distance sensors.</p>
	</figure>
	<p>Not wanting to merely recreate a multitouch surface, we explored a finer subset of such gestures and sought to understand if constraining the user to a single axis would be a viable alternative to 2-dimensional input in limited use-cases. Given a single axis and (optionally) two hands, we envisioned how the user would input key commands, select objects and navigate menu items.</p>
	<p>Each of the table's four sides provides independent controls to the system, allowing up to four simultaneous users. All gestures is derivative of user hand placement relative to the edge of the table.<sup>2</sup> By gesturing with two hands, the user introduces a length variable (i.e. the distance between the hands) as an additional input, providing an opportunity for relatively complex gestural interactions.</p>
	<p>To acquire such distance input, the most economical and reliable method is placing <a href="http://en.wikipedia.org/wiki/Infrared">infrared</a> distance sensors along the corners of the table, facing inward toward the middle of their respective sides. Each side, monitored by <a href="http://www.trossenrobotics.com/sharp-ir-distance-sensor-gp2y0a02yk.aspx">sensors</a> on its two corners, interprets two hands (or objects) placed along the side as an input.<sup>3</sup> By relying on <a href="http://www.phidgets.com/">Phidgets</a> as a middle-layer between the sensors and Flex, Ping receives and adapts the data, converting it to actionable ActionScript 3 events to be interpreted by any software layer.</p>
	
	<h3>Ping Pong game</h3>
	<p>As a first attempt at designing a Ping multiplayer game, we created a clone of <a href="http://www.atari.com/">Atari's</a> classic <a href="http://en.wikipedia.org/wiki/Pong">Pong game</a>.<sup>1</sup> The users' hand motion directly correlates to the placement of their respective paddles.</p>
	<p>However, after much testing and software data correction, the gaming experi&shy;ence, though playable, was simply not transparent enough to continue this idea further within budgetary constraints. Provided the <abbr title="Infared">IR</abbr> line-of-sight is essentially tunnel-vision, the user would need to be extraordinarily consistent with strict hand movements to ensure long-term reliable input.</p>
	
